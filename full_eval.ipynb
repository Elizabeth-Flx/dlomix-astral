{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 13:19:09.084548: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-15 13:19:09.143366: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 13:19:09.143401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 13:19:09.145371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 13:19:09.154286: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-15 13:19:09.155217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 13:19:12.864848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/nfs/home/students/d.lochert/miniconda3/envs/astral/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliable feature extractors are (use the key of the following dict and pass it to features_to_extract in the Dataset Class):\n",
      "{\n",
      "   \"atom_count\": \"Atom count of PTM.\",\n",
      "   \"delta_mass\": \"Delta mass of PTM.\",\n",
      "   \"mod_gain\": \"Gain of atoms due to PTM.\",\n",
      "   \"mod_loss\": \"Loss of atoms due to PTM.\",\n",
      "   \"red_smiles\": \"Reduced SMILES representation of PTM.\"\n",
      "}.\n",
      "When writing your own feature extractor, you can either\n",
      "    (1) use the FeatureExtractor class or\n",
      "    (2) write a function that can be mapped to the Hugging Face dataset.\n",
      "In both cases, you can access the parsed sequence information from the dataset using the following keys, which all provide python lists:\n",
      "    - _parsed_sequence: parsed sequence\n",
      "    - _n_term_mods: N-terminal modifications\n",
      "    - _c_term_mods: C-terminal modifications\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "from dlomix.data import FragmentIonIntensityDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['penult_sum',\n",
       " 'single_both',\n",
       " 'single_mult',\n",
       " 'single_sum',\n",
       " 'FiLM_reduced',\n",
       " 'FiLM_full',\n",
       " 'token_mult',\n",
       " 'token_sum',\n",
       " 'single_token',\n",
       " 'multi_token']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [\n",
    "    #\"f_r_embed_input_d5_static_0.0005_28j\",\n",
    "    #\"f_r_penult_mult_d5_static_0.0005_Ag0\",\n",
    "    \"f_r_penult_sum_d5_static_0.0005_370\",\n",
    "    \"f_r_single_both_d5_static_0.0005_GTs\",\n",
    "    \"f_r_single_mult_d5_static_0.0005_JT1\",\n",
    "    \"f_r_single_sum_d5_static_0.0005_F8t\",\n",
    "    \"f_r_FiLM_reduced_d5_static_0.0005_9vG\",\n",
    "    \"f_r_FiLM_full_d5_static_0.0005_XOr\",\n",
    "    \"f_r_token_mult_d5_static_0.0005_eW4\",\n",
    "    \"f_r_token_sum_d5_static_0.0005_9I4\",\n",
    "    \"f_r_single_token_d5_static_0.0005_lm6\",\n",
    "    \"f_r_multi_token_d5_static_0.0005_RvL\",\n",
    "]\n",
    "\n",
    "model_labels = [name.split('_r_')[1].split('_d5_')[0] for name in model_names]\n",
    "model_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_r_single_sum_d5_static_0.0005_F8t\n",
      "Model: \"transformer_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             multiple                  6656      \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  3328      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " trans_block_5 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_6 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_7 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_8 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_9 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  131584    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (1024, 30, 512)           1024      \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  89262     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3176372 (12.12 MB)\n",
      "Trainable params: 2920372 (11.14 MB)\n",
      "Non-trainable params: 256000 (1000.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(model_names[5])\n",
    "\n",
    "model = keras.saving.load_model('/cmnfs/proj/prosit_astral/saved_models/final_models/%s.keras' % model_names[5],\n",
    "                                custom_objects={'masked_spectral_distance': masked_spectral_distance, 'masked_pearson_correlation_distance': masked_pearson_correlation_distance}, \n",
    "                                compile=True, safe_mode=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = FragmentIonIntensityDataset.load_from_disk(\"/cmnfs/proj/prosit_astral/datasets/_dlomix_saved/full_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss:  tf.Tensor(0.111140825, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.106149524, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10574724, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10824153, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.11211727, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10623449, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10637877, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10645366, shape=(), dtype=float32)\n",
      "0\n",
      "Loss:  tf.Tensor(0.10725694, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.02740276, 0.13804853, 0.11117673, ..., 0.06125546, 0.0870994 ,\n",
      "       0.05810995], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01733022, 0.12754469, 0.10577754, ..., 0.05156828, 0.07514353,\n",
      "       0.0578772 ], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01783858, 0.10208219, 0.11496042, ..., 0.05492929, 0.06300247,\n",
      "       0.06081626], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01880644, 0.11530199, 0.09523156, ..., 0.05186801, 0.06559247,\n",
      "       0.04282527], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01186958, 0.10691382, 0.10866486, ..., 0.04737495, 0.0693258 ,\n",
      "       0.10058474], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.02843363, 0.13083836, 0.12347692, ..., 0.0610521 , 0.08672579,\n",
      "       0.03307744], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01629857, 0.17298225, 0.11046822, ..., 0.05875249, 0.05264596,\n",
      "       0.02987504], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01665778, 0.15701894, 0.1017153 , ..., 0.05125406, 0.0443598 ,\n",
      "       0.05636369], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([0.01835261, 0.12411316, 0.0898908 , ..., 0.05408711, 0.05537704,\n",
      "       0.05946218], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "eval_batches = [m for m in int_data.tensor_val_data.take(1)]\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    model = keras.saving.load_model('/cmnfs/proj/prosit_astral/saved_models/final_models/%s.keras' % model_name,\n",
    "                                custom_objects={'masked_spectral_distance': masked_spectral_distance, 'masked_pearson_correlation_distance': masked_pearson_correlation_distance}, \n",
    "                                compile=True, safe_mode=True)\n",
    "    \n",
    "    pred = []\n",
    "    true = []\n",
    "    \n",
    "    for j in range(len(eval_batches)):\n",
    "    \n",
    "        predictions = model.predict(eval_batches[j][0], verbose=0)\n",
    "    \n",
    "        pred += np.split(predictions,        predictions.shape[0], axis=0) \n",
    "        true += np.split(eval_batches[j][1], predictions.shape[0], axis=0) \n",
    "    \n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    true = np.concatenate(true, axis=0)\n",
    "    \n",
    "    print('Loss: ', tf.reduce_mean( masked_spectral_distance(true, pred) ))\n",
    "\n",
    "    losses.append(masked_spectral_distance(true, pred))\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (44774526.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    'method': np.repeat(model_labels, 1024)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "test = pd.DataFrame({\n",
    "    'method': np.repeat(model_labels, 1024)\n",
    "    'loss': tf.concat(losses, axis=0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               method  number  orbital_period   mass  distance  year\n",
      "0     Radial Velocity       1      269.300000   7.10     77.40  2006\n",
      "1     Radial Velocity       1      874.774000   2.21     56.95  2008\n",
      "2     Radial Velocity       1      763.000000   2.60     19.84  2011\n",
      "3     Radial Velocity       1      326.030000  19.40    110.62  2007\n",
      "4     Radial Velocity       1      516.220000  10.50    119.47  2009\n",
      "...               ...     ...             ...    ...       ...   ...\n",
      "1030          Transit       1        3.941507    NaN    172.00  2006\n",
      "1031          Transit       1        2.615864    NaN    148.00  2007\n",
      "1032          Transit       1        3.191524    NaN    174.00  2007\n",
      "1033          Transit       1        4.125083    NaN    293.00  2008\n",
      "1034          Transit       1        4.187757    NaN    260.00  2008\n",
      "\n",
      "[1035 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# Load the example planets dataset\n",
    "planets = sns.load_dataset(\"planets\")\n",
    "\n",
    "print(planets)\n",
    "\n",
    "# Plot the orbital period with horizontal boxes\n",
    "# sns.boxplot(\n",
    "#     planets, x=\"distance\", y=\"method\", hue=\"method\",\n",
    "#     whis=[0, 100], width=.6, palette=\"vlag\"\n",
    "# )\n",
    "\n",
    "sns.boxplot(\n",
    "    test, x=\"loss\", y=\"method\",\n",
    "    whis=[0, 100], width=.6, palette=\"vlag\"\n",
    ")\n",
    "\n",
    "\n",
    "# Add in points to show each observation\n",
    "# sns.stripplot(planets, x=\"distance\", y=\"method\", size=4, color=\".3\")\n",
    "\n",
    "# Tweak the visual presentation\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
