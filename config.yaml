# large or small dataset

dataloader:
  dataset: full      # full | small
  batch_size: 2048   # default 2048
#  save_path: /cmnfs/proj/prosit_astral/datasets/parquet

model_type: ours
model_settings:
  running_units: 256          # 256
  d: 64                       # 64
  h: 6                        # 6
  depth: 3                    # 8         
  ffn_mult: 1
  penultimate_units: 512
  alphabet: False
  dropout: 0.1
  integration_method: FiLM_small        # embed_input | multi_token | single_token | token_summation | inject | adaptive
  norm_type: layer               # layer | batch | adaptive
  inject_pre: True          # inject before Attention block
  inject_post: False         # inject into FFN
  inject_position: all      # all | first | last | none
  learned_pos: False

prosit:
  model_d: 128 # 64
  embedding_output_dim: 32 # 64
  ff_dim: 256 # 32
  num_heads: 16 # 16
  num_transformers: 6 # 8
  penult_d: 512 # 256
  len_fion: 6 # 6
  dense_dim_factor: 8 # 8
  dropout_rate: 0 # 0
  seq_length: 30 # 30
  transformer_dropout: 0 # 0.1
  

train_settings:
  epochs: 10
  lr_base: 0.0005

  lr_method: static      # static | geometric | linear
  
  lr_geometric: [5, 0.0005, 0.5, 1]
  lr_linear: [5, 10, 0.0005, 0.00005]

  seed: 42                             # doesnt quite work yet
  log_wandb: True

wandb_settings:
  log_wandb: True
  name: None
  project: 18-06_Benchmark
