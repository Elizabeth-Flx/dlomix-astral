# large or small dataset

dataloader:
  dataset: combined      # full | small
  batch_size: 1024   # default 2048
  load_data: True

model_type: ours
model_settings:
  running_units: 256          # 256
  d: 64                       # 64
  h: 6                        # 6
  depth: 10                    # 10 | 3     
  ffn_mult: 1 
  penultimate_units: 512
  alphabet: False
  dropout: 0.1
  integration_method: multi_token        # embed_input | multi_token | single_token | token_summation | inject | adaptive
  norm_type: layer               # layer | batch | adaptive
  inject_pre: True          # inject before Attention block
  inject_post: False         # inject into FFN
  inject_position: all      # all | first | last | none
  learned_pos: False
  identiy_metadata: False

train_settings:
  epochs: 20
  lr_base: 0.0005
  lr_method: static      # static | geometric | linear
  
  lr_geometric: [5, 0.0005, 0.5, 1]
  lr_linear: [5, 10, 0.0005, 0.00005]

  seed: 42                             # doesnt quite work yet
  log_wandb: True

wandb_settings:
  log_wandb: True
  # name: test_run
  project: combined_data_identity_testing
