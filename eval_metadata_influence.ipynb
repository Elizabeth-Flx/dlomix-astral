{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 15:04:57.559552: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-16 15:04:57.616226: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-16 15:04:57.616264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-16 15:04:57.618305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-16 15:04:57.627497: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-16 15:04:57.630643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 15:05:05.592849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/nfs/home/students/d.lochert/miniconda3/envs/astral/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliable feature extractors are (use the key of the following dict and pass it to features_to_extract in the Dataset Class):\n",
      "{\n",
      "   \"atom_count\": \"Atom count of PTM.\",\n",
      "   \"delta_mass\": \"Delta mass of PTM.\",\n",
      "   \"mod_gain\": \"Gain of atoms due to PTM.\",\n",
      "   \"mod_loss\": \"Loss of atoms due to PTM.\",\n",
      "   \"red_smiles\": \"Reduced SMILES representation of PTM.\"\n",
      "}.\n",
      "When writing your own feature extractor, you can either\n",
      "    (1) use the FeatureExtractor class or\n",
      "    (2) write a function that can be mapped to the Hugging Face dataset.\n",
      "In both cases, you can access the parsed sequence information from the dataset using the following keys, which all provide python lists:\n",
      "    - _parsed_sequence: parsed sequence\n",
      "    - _n_term_mods: N-terminal modifications\n",
      "    - _c_term_mods: C-terminal modifications\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "from dlomix.data import FragmentIonIntensityDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  6656      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  3328      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1315840   \n",
      "                                                                 \n",
      " trans_block (TransBlock)    multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_1 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_2 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_3 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_4 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_5 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_6 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_7 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_8 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " trans_block_9 (TransBlock)  multiple                  524545    \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  131584    \n",
      "                                                                 \n",
      " sequential (Sequential)     (1024, 30, 512)           1024      \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  89262     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7049145 (26.89 MB)\n",
      "Trainable params: 6793145 (25.91 MB)\n",
      "Non-trainable params: 256000 (1000.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'c_i_FiLM_full_d10_static_0.0005_P4k'\n",
    "\n",
    "model = keras.saving.load_model('/nfs/home/students/d.lochert/projects/astral/dlomix-astral/saved_models/%s.keras' % model_name,\n",
    "                                custom_objects={'masked_spectral_distance': masked_spectral_distance, 'masked_pearson_correlation_distance': masked_pearson_correlation_distance}, \n",
    "                                compile=True, safe_mode=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = FragmentIonIntensityDataset.load_from_disk(\"/nfs/home/students/d.lochert/projects/astral/dlomix-astral/combined_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'modified_sequence': <tf.Tensor: shape=(1024, 30), dtype=int64, numpy=\n",
       "  array([[11,  6,  1, ...,  0,  0,  0],\n",
       "         [ 1, 16, 14, ...,  0,  0,  0],\n",
       "         [ 8, 13, 18, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 4, 10, 16, ...,  0,  0,  0],\n",
       "         [ 4, 18, 17, ...,  0,  0,  0],\n",
       "         [ 4, 17,  7, ...,  0,  0,  0]])>,\n",
       "  'charge_oh': <tf.Tensor: shape=(1024, 6), dtype=float32, numpy=\n",
       "  array([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]], dtype=float32)>,\n",
       "  'collision_energy': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       "  array([0.2382246, 0.3      , 0.29     , ..., 0.3      , 0.3      ,\n",
       "         0.27     ], dtype=float32)>,\n",
       "  'method_nr_oh': <tf.Tensor: shape=(1024, 2), dtype=float32, numpy=\n",
       "  array([[0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         ...,\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.]], dtype=float32)>,\n",
       "  'machine_oh': <tf.Tensor: shape=(1024, 3), dtype=float32, numpy=\n",
       "  array([[0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.]], dtype=float32)>},\n",
       " <tf.Tensor: shape=(1024, 174), dtype=float32, numpy=\n",
       " array([[ 0.02702703,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.7972761 ,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.13773921,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_batch = [m for m in int_data.tensor_train_data.take(42)][0][0]\n",
    "\n",
    "test_batch = [m for m in int_data.tensor_val_data.take(42)][1]\n",
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_suffled_batch(batch, attribute_name='all'):\n",
    "    shuffled_batch = batch.copy()\n",
    "\n",
    "    if attribute_name == 'all':\n",
    "        shuffled_batch['charge_oh'] = tf.random.shuffle(shuffled_batch['charge_oh'])\n",
    "        shuffled_batch['collision_energy'] = tf.random.shuffle(shuffled_batch['collision_energy'])\n",
    "        shuffled_batch['method_nr_oh'] = tf.random.shuffle(shuffled_batch['method_nr_oh'])\n",
    "        shuffled_batch['machine_oh'] = tf.random.shuffle(shuffled_batch['machine_oh'])\n",
    "\n",
    "        return shuffled_batch\n",
    "    \n",
    "    else:\n",
    "        shuffled_batch[attribute_name] = tf.random.shuffle(shuffled_batch[attribute_name])\n",
    "        return shuffled_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 138ms/step\n",
      "32/32 [==============================] - 4s 135ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 133ms/step\n",
      "32/32 [==============================] - 4s 139ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 145ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 143ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 149ms/step\n",
      "32/32 [==============================] - 5s 146ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 148ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "0.17815964\n",
      "0.3675637\n",
      "0.21478792\n",
      "0.32385594\n",
      "0.40777493\n",
      "0.54132795\n"
     ]
    }
   ],
   "source": [
    "loss_normal = []\n",
    "loss_charge = []\n",
    "loss_collis = []\n",
    "loss_method = []\n",
    "loss_machin = []\n",
    "loss_all = []\n",
    "\n",
    "\n",
    "\n",
    "test_batches = [m for m in int_data.tensor_val_data.take(5)]\n",
    "\n",
    "for test_batch in test_batches:\n",
    "\n",
    "    test_batch_normal = test_batch[0]\n",
    "    test_batch_charge = make_suffled_batch(test_batch_normal, 'charge_oh')\n",
    "    test_batch_collis = make_suffled_batch(test_batch_normal, 'collision_energy')\n",
    "    test_batch_method = make_suffled_batch(test_batch_normal, 'method_nr_oh')\n",
    "    test_batch_machin = make_suffled_batch(test_batch_normal, 'machine_oh')\n",
    "    test_batch_all = make_suffled_batch(test_batch_normal, 'all')\n",
    "\n",
    "    loss_normal.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_normal)) ))\n",
    "    loss_charge.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_charge)) ))\n",
    "    loss_collis.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_collis)) ))\n",
    "    loss_method.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_method)) ))\n",
    "    loss_machin.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_machin)) ))\n",
    "    loss_all.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_all)) ))\n",
    "\n",
    "print(np.mean(loss_normal))\n",
    "print(np.mean(loss_charge))\n",
    "print(np.mean(loss_collis))\n",
    "print(np.mean(loss_method))\n",
    "print(np.mean(loss_machin))\n",
    "print(np.mean(loss_all))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modified_sequence': <tf.Tensor: shape=(1024, 30), dtype=int64, numpy=\n",
       " array([[11,  6,  1, ...,  0,  0,  0],\n",
       "        [ 1, 16, 14, ...,  0,  0,  0],\n",
       "        [ 8, 13, 18, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 4, 10, 16, ...,  0,  0,  0],\n",
       "        [ 4, 18, 17, ...,  0,  0,  0],\n",
       "        [ 4, 17,  7, ...,  0,  0,  0]])>,\n",
       " 'charge_oh': <tf.Tensor: shape=(1024, 6), dtype=float32, numpy=\n",
       " array([[0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=float32)>,\n",
       " 'collision_energy': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       " array([0.2382246, 0.3      , 0.29     , ..., 0.3      , 0.3      ,\n",
       "        0.27     ], dtype=float32)>,\n",
       " 'method_nr_oh': <tf.Tensor: shape=(1024, 2), dtype=float32, numpy=\n",
       " array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32)>,\n",
       " 'machine_oh': <tf.Tensor: shape=(1024, 3), dtype=float32, numpy=\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]], dtype=float32)>}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle metadata\n",
    "shuffled_batch = test_batch[0].copy()\n",
    "\n",
    "# shuffled_batch['charge_oh'] = tf.random.shuffle(shuffled_batch['charge_oh'])\n",
    "# shuffled_batch['collision_energy'] = tf.random.shuffle(shuffled_batch['collision_energy'])\n",
    "# shuffled_batch['method_nr_oh'] = tf.random.shuffle(shuffled_batch['method_nr_oh'])\n",
    "shuffled_batch['machine_oh'] = tf.random.shuffle(shuffled_batch['machine_oh'])\n",
    "\n",
    "shuffled_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 136ms/step\n",
      "tf.Tensor(0.16962747, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39736664, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_prediction = model.predict(test_batch[0])\n",
    "shuffled_batch_prediction = model.predict(shuffled_batch)\n",
    "\n",
    "print(tf.reduce_mean( masked_spectral_distance(test_batch[1], batch_prediction) ))\n",
    "print(tf.reduce_mean( masked_spectral_distance(test_batch[1], shuffled_batch_prediction) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 134ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 135ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 131ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "17/17 [==============================] - 4s 153ms/step\n",
      "AST:  tf.Tensor(0.21113022, shape=(), dtype=float32)\n",
      "TOF:  tf.Tensor(0.16155638, shape=(), dtype=float32)\n",
      "LUM:  tf.Tensor(0.16276914, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eval_batches = [m for m in int_data.tensor_val_data.take(50)]\n",
    "\n",
    "pred_ast = []\n",
    "pred_tof = []\n",
    "pred_lum = []\n",
    "\n",
    "true_ast = []\n",
    "true_tof = []\n",
    "true_lum = []\n",
    "\n",
    "\n",
    "for j in range(len(eval_batches)):\n",
    "\n",
    "    pred = model.predict(eval_batches[j][0])\n",
    "\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    mach = np.split(eval_batches[j][0]['machine_oh'], batch_size, axis=0)\n",
    "    pred = np.split(pred, batch_size, axis=0)\n",
    "    true = np.split(eval_batches[j][1], batch_size, axis=0)\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        if np.argmax(mach[i]) == 0:\n",
    "            pred_ast.append(pred[i])\n",
    "            true_ast.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 1:\n",
    "            pred_tof.append(pred[i])\n",
    "            true_tof.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 2:\n",
    "            pred_lum.append(pred[i])\n",
    "            true_lum.append(true[i])\n",
    "\n",
    "pred_ast = np.concatenate(pred_ast, axis=0)\n",
    "pred_tof = np.concatenate(pred_tof, axis=0)\n",
    "pred_lum = np.concatenate(pred_lum, axis=0)\n",
    "\n",
    "true_ast = np.concatenate(true_ast, axis=0)\n",
    "true_tof = np.concatenate(true_tof, axis=0)\n",
    "true_lum = np.concatenate(true_lum, axis=0)\n",
    "\n",
    "print('AST: ', tf.reduce_mean( masked_spectral_distance(true_ast, pred_ast) ))\n",
    "print('TOF: ', tf.reduce_mean( masked_spectral_distance(true_tof, pred_tof) ))\n",
    "print('LUM: ', tf.reduce_mean( masked_spectral_distance(true_lum, pred_lum) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 123ms/step\n",
      "32/32 [==============================] - 4s 122ms/step\n",
      "32/32 [==============================] - 4s 123ms/step\n",
      "32/32 [==============================] - 4s 124ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "CID:  tf.Tensor(0.2084779, shape=(), dtype=float32)\n",
      "HCD:  tf.Tensor(0.15689628, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eval_batches = [m for m in int_data.tensor_val_data.take(50)]\n",
    "\n",
    "pred_cid = []\n",
    "pred_hcd = []\n",
    "\n",
    "true_cid = []\n",
    "true_hcd = []\n",
    "\n",
    "\n",
    "for j in range(len(eval_batches)):\n",
    "\n",
    "    pred = model.predict(eval_batches[j][0])\n",
    "\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    mach = np.split(eval_batches[j][0]['method_nr_oh'], batch_size, axis=0)\n",
    "    pred = np.split(pred, batch_size, axis=0)\n",
    "    true = np.split(eval_batches[j][1], batch_size, axis=0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        if np.argmax(mach[i]) == 0:\n",
    "            pred_cid.append(pred[i])\n",
    "            true_cid.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 1:\n",
    "            pred_hcd.append(pred[i])\n",
    "            true_hcd.append(true[i])\n",
    "\n",
    "pred_cid = np.concatenate(pred_cid, axis=0)\n",
    "pred_hcd = np.concatenate(pred_hcd, axis=0)\n",
    "\n",
    "true_cid = np.concatenate(true_cid, axis=0)\n",
    "true_hcd = np.concatenate(true_hcd, axis=0)\n",
    "\n",
    "print('CID: ', tf.reduce_mean( masked_spectral_distance(true_cid, pred_cid) ))\n",
    "print('HCD: ', tf.reduce_mean( masked_spectral_distance(true_hcd, pred_hcd) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
