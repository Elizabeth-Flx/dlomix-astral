{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "from dlomix.data import FragmentIonIntensityDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            multiple                  6656      \n",
      "                                                                 \n",
      " dense_26 (Dense)            multiple                  3328      \n",
      "                                                                 \n",
      " dense_27 (Dense)            multiple                  131584    \n",
      "                                                                 \n",
      " trans_block_25 (TransBlock  multiple                  524545    \n",
      " )                                                               \n",
      "                                                                 \n",
      " trans_block_26 (TransBlock  multiple                  524545    \n",
      " )                                                               \n",
      "                                                                 \n",
      " trans_block_27 (TransBlock  multiple                  524545    \n",
      " )                                                               \n",
      "                                                                 \n",
      " trans_block_28 (TransBlock  multiple                  524545    \n",
      " )                                                               \n",
      "                                                                 \n",
      " trans_block_29 (TransBlock  multiple                  524545    \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_28 (Dense)            multiple                  131584    \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (1024, 30, 512)           1024      \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  89262     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3242164 (12.37 MB)\n",
      "Trainable params: 2986164 (11.39 MB)\n",
      "Non-trainable params: 256000 (1000.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'f_r_single_both_d5_static_0.0005_aoQ'\n",
    "model_name = 'b_r_single_both_d5_static_0.0005_99A'\n",
    "model_name = 'p_r_single_both_d5_static_0.0005_XQO'\n",
    "model_name = 'b_r_single_both_d5_static_0.0005_5DA'\n",
    "\n",
    "model = keras.saving.load_model('/nfs/home/students/d.lochert/projects/astral/dlomix-astral/saved_models/%s.keras' % model_name,\n",
    "                                custom_objects={'masked_spectral_distance': masked_spectral_distance, 'masked_pearson_correlation_distance': masked_pearson_correlation_distance}, \n",
    "                                compile=True, safe_mode=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = FragmentIonIntensityDataset.load_from_disk(\"/cmnfs/proj/prosit_astral/datasets/_dlomix_saved/full_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'modified_sequence': <tf.Tensor: shape=(1024, 30), dtype=int64, numpy=\n",
       "  array([[11,  6,  1, ...,  0,  0,  0],\n",
       "         [ 1, 16, 14, ...,  0,  0,  0],\n",
       "         [ 8, 13, 18, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 4, 10, 16, ...,  0,  0,  0],\n",
       "         [ 4, 18, 17, ...,  0,  0,  0],\n",
       "         [ 4, 17,  7, ...,  0,  0,  0]])>,\n",
       "  'charge_oh': <tf.Tensor: shape=(1024, 6), dtype=float32, numpy=\n",
       "  array([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]], dtype=float32)>,\n",
       "  'collision_energy': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       "  array([0.2382246, 0.3      , 0.29     , ..., 0.3      , 0.3      ,\n",
       "         0.27     ], dtype=float32)>,\n",
       "  'method_nr_oh': <tf.Tensor: shape=(1024, 2), dtype=float32, numpy=\n",
       "  array([[0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         ...,\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.]], dtype=float32)>,\n",
       "  'machine_oh': <tf.Tensor: shape=(1024, 3), dtype=float32, numpy=\n",
       "  array([[0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.]], dtype=float32)>},\n",
       " <tf.Tensor: shape=(1024, 174), dtype=float32, numpy=\n",
       " array([[ 0.02702703,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.7972761 ,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.13773921,  0.        ,  0.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_batch = [m for m in int_data.tensor_train_data.take(42)][0][0]\n",
    "\n",
    "test_batch = [m for m in int_data.tensor_val_data.take(42)][1]\n",
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_suffled_batch(batch, attribute_name='all'):\n",
    "    shuffled_batch = batch.copy()\n",
    "\n",
    "    if attribute_name == 'all':\n",
    "        shuffled_batch['charge_oh'] = tf.random.shuffle(shuffled_batch['charge_oh'])\n",
    "        shuffled_batch['collision_energy'] = tf.random.shuffle(shuffled_batch['collision_energy'])\n",
    "        shuffled_batch['method_nr_oh'] = tf.random.shuffle(shuffled_batch['method_nr_oh'])\n",
    "        shuffled_batch['machine_oh'] = tf.random.shuffle(shuffled_batch['machine_oh'])\n",
    "\n",
    "        return shuffled_batch\n",
    "    \n",
    "    else:\n",
    "        shuffled_batch[attribute_name] = tf.random.shuffle(shuffled_batch[attribute_name])\n",
    "        return shuffled_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 138ms/step\n",
      "32/32 [==============================] - 4s 135ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 133ms/step\n",
      "32/32 [==============================] - 4s 139ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 145ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 143ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "32/32 [==============================] - 5s 141ms/step\n",
      "32/32 [==============================] - 5s 140ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 149ms/step\n",
      "32/32 [==============================] - 5s 146ms/step\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "32/32 [==============================] - 5s 148ms/step\n",
      "32/32 [==============================] - 5s 142ms/step\n",
      "0.17815964\n",
      "0.3675637\n",
      "0.21478792\n",
      "0.32385594\n",
      "0.40777493\n",
      "0.54132795\n"
     ]
    }
   ],
   "source": [
    "loss_normal = []\n",
    "loss_charge = []\n",
    "loss_collis = []\n",
    "loss_method = []\n",
    "loss_machin = []\n",
    "loss_all = []\n",
    "\n",
    "\n",
    "\n",
    "test_batches = [m for m in int_data.tensor_val_data.take(5)]\n",
    "\n",
    "for test_batch in test_batches:\n",
    "\n",
    "    test_batch_normal = test_batch[0]\n",
    "    test_batch_charge = make_suffled_batch(test_batch_normal, 'charge_oh')\n",
    "    test_batch_collis = make_suffled_batch(test_batch_normal, 'collision_energy')\n",
    "    test_batch_method = make_suffled_batch(test_batch_normal, 'method_nr_oh')\n",
    "    test_batch_machin = make_suffled_batch(test_batch_normal, 'machine_oh')\n",
    "    test_batch_all = make_suffled_batch(test_batch_normal, 'all')\n",
    "\n",
    "    loss_normal.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_normal)) ))\n",
    "    loss_charge.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_charge)) ))\n",
    "    loss_collis.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_collis)) ))\n",
    "    loss_method.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_method)) ))\n",
    "    loss_machin.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_machin)) ))\n",
    "    loss_all.append(tf.reduce_mean( masked_spectral_distance(test_batch[1], model.predict(test_batch_all)) ))\n",
    "\n",
    "print(np.mean(loss_normal))\n",
    "print(np.mean(loss_charge))\n",
    "print(np.mean(loss_collis))\n",
    "print(np.mean(loss_method))\n",
    "print(np.mean(loss_machin))\n",
    "print(np.mean(loss_all))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modified_sequence': <tf.Tensor: shape=(1024, 30), dtype=int64, numpy=\n",
       " array([[11,  6,  1, ...,  0,  0,  0],\n",
       "        [ 1, 16, 14, ...,  0,  0,  0],\n",
       "        [ 8, 13, 18, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 4, 10, 16, ...,  0,  0,  0],\n",
       "        [ 4, 18, 17, ...,  0,  0,  0],\n",
       "        [ 4, 17,  7, ...,  0,  0,  0]])>,\n",
       " 'charge_oh': <tf.Tensor: shape=(1024, 6), dtype=float32, numpy=\n",
       " array([[0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=float32)>,\n",
       " 'collision_energy': <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       " array([0.2382246, 0.3      , 0.29     , ..., 0.3      , 0.3      ,\n",
       "        0.27     ], dtype=float32)>,\n",
       " 'method_nr_oh': <tf.Tensor: shape=(1024, 2), dtype=float32, numpy=\n",
       " array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32)>,\n",
       " 'machine_oh': <tf.Tensor: shape=(1024, 3), dtype=float32, numpy=\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]], dtype=float32)>}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle metadata\n",
    "shuffled_batch = test_batch[0].copy()\n",
    "\n",
    "# shuffled_batch['charge_oh'] = tf.random.shuffle(shuffled_batch['charge_oh'])\n",
    "# shuffled_batch['collision_energy'] = tf.random.shuffle(shuffled_batch['collision_energy'])\n",
    "# shuffled_batch['method_nr_oh'] = tf.random.shuffle(shuffled_batch['method_nr_oh'])\n",
    "shuffled_batch['machine_oh'] = tf.random.shuffle(shuffled_batch['machine_oh'])\n",
    "\n",
    "shuffled_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 136ms/step\n",
      "tf.Tensor(0.16962747, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39736664, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_prediction = model.predict(test_batch[0])\n",
    "shuffled_batch_prediction = model.predict(shuffled_batch)\n",
    "\n",
    "print(tf.reduce_mean( masked_spectral_distance(test_batch[1], batch_prediction) ))\n",
    "print(tf.reduce_mean( masked_spectral_distance(test_batch[1], shuffled_batch_prediction) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 71ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 70ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 70ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 68ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 70ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "AST:  tf.Tensor(0.23037277, shape=(), dtype=float32)\n",
      "TOF:  tf.Tensor(0.16874826, shape=(), dtype=float32)\n",
      "LUM:  tf.Tensor(0.17807077, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eval_batches = [m for m in int_data.tensor_val_data.take(50)]\n",
    "\n",
    "pred_ast = []\n",
    "pred_tof = []\n",
    "pred_lum = []\n",
    "\n",
    "true_ast = []\n",
    "true_tof = []\n",
    "true_lum = []\n",
    "\n",
    "\n",
    "for j in range(len(eval_batches)):\n",
    "\n",
    "    pred = model.predict(eval_batches[j][0])\n",
    "\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    mach = np.split(eval_batches[j][0]['machine_oh'], batch_size, axis=0)\n",
    "    pred = np.split(pred, batch_size, axis=0)\n",
    "    true = np.split(eval_batches[j][1], batch_size, axis=0)\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        if np.argmax(mach[i]) == 0:\n",
    "            pred_ast.append(pred[i])\n",
    "            true_ast.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 1:\n",
    "            pred_tof.append(pred[i])\n",
    "            true_tof.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 2:\n",
    "            pred_lum.append(pred[i])\n",
    "            true_lum.append(true[i])\n",
    "\n",
    "pred_ast = np.concatenate(pred_ast, axis=0)\n",
    "pred_tof = np.concatenate(pred_tof, axis=0)\n",
    "pred_lum = np.concatenate(pred_lum, axis=0)\n",
    "\n",
    "true_ast = np.concatenate(true_ast, axis=0)\n",
    "true_tof = np.concatenate(true_tof, axis=0)\n",
    "true_lum = np.concatenate(true_lum, axis=0)\n",
    "\n",
    "print('AST: ', tf.reduce_mean( masked_spectral_distance(true_ast, pred_ast) ))\n",
    "print('TOF: ', tf.reduce_mean( masked_spectral_distance(true_tof, pred_tof) ))\n",
    "print('LUM: ', tf.reduce_mean( masked_spectral_distance(true_lum, pred_lum) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 132ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 130ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 123ms/step\n",
      "32/32 [==============================] - 4s 122ms/step\n",
      "32/32 [==============================] - 4s 123ms/step\n",
      "32/32 [==============================] - 4s 124ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 129ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 128ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "32/32 [==============================] - 4s 126ms/step\n",
      "32/32 [==============================] - 4s 127ms/step\n",
      "CID:  tf.Tensor(0.2084779, shape=(), dtype=float32)\n",
      "HCD:  tf.Tensor(0.15689628, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eval_batches = [m for m in int_data.tensor_val_data.take(50)]\n",
    "\n",
    "pred_cid = []\n",
    "pred_hcd = []\n",
    "\n",
    "true_cid = []\n",
    "true_hcd = []\n",
    "\n",
    "\n",
    "for j in range(len(eval_batches)):\n",
    "\n",
    "    pred = model.predict(eval_batches[j][0])\n",
    "\n",
    "    batch_size = pred.shape[0]\n",
    "\n",
    "    mach = np.split(eval_batches[j][0]['method_nr_oh'], batch_size, axis=0)\n",
    "    pred = np.split(pred, batch_size, axis=0)\n",
    "    true = np.split(eval_batches[j][1], batch_size, axis=0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        if np.argmax(mach[i]) == 0:\n",
    "            pred_cid.append(pred[i])\n",
    "            true_cid.append(true[i])\n",
    "        elif np.argmax(mach[i]) == 1:\n",
    "            pred_hcd.append(pred[i])\n",
    "            true_hcd.append(true[i])\n",
    "\n",
    "pred_cid = np.concatenate(pred_cid, axis=0)\n",
    "pred_hcd = np.concatenate(pred_hcd, axis=0)\n",
    "\n",
    "true_cid = np.concatenate(true_cid, axis=0)\n",
    "true_hcd = np.concatenate(true_hcd, axis=0)\n",
    "\n",
    "print('CID: ', tf.reduce_mean( masked_spectral_distance(true_cid, pred_cid) ))\n",
    "print('HCD: ', tf.reduce_mean( masked_spectral_distance(true_hcd, pred_hcd) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
